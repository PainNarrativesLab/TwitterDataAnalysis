{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:37.320840Z",
     "start_time": "2018-04-06T23:17:37.318419Z"
    }
   },
   "outputs": [],
   "source": [
    "#### This notebook is dedicated to determining which users are pain patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ToDo\n",
    "\n",
    "* Isolate people who have only texted about migraine vs. crps (etc). Look for systematic differences\n",
    "* Do analysis on all words in texts\n",
    "* Try doing the analysis on twitter users rather than tweets\n",
    "* Combine terms like 'fibro' and 'fibromyalgia'\n",
    "* Store lists of things to ignore/combine/categorize etc in spreadsheet and import?\n",
    "\n",
    "### Notes\n",
    "SQL query for counting tweets in which hashtag used:\n",
    "SELECT h.hashtag, count(t.tweetID) AS totTweets FROM hashtags h INNER JOIN tweetsXtags t ON h.tagID = t.tagID GROUP BY hashtag ORDER BY totTweets DESC ;\n",
    "\n",
    "#### This cell was imported from twitter_data_analysis 11/9/16\n",
    "That was not the last time this notebook was updated "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Base imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T23:00:38.677926Z",
     "start_time": "2018-04-16T23:00:37.140062Z"
    }
   },
   "outputs": [],
   "source": [
    "#standard lib\n",
    "import os\n",
    "import string\n",
    "\n",
    "#other people's property\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import sqlalchemy\n",
    "\n",
    "#Plotting \n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-16T23:00:38.687606Z",
     "start_time": "2018-04-16T23:00:38.680791Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#Base Classes stuff\n",
    "from FileSystemTools import *\n",
    "from UtilityDecorators import *\n",
    "from UtilityFunctions import *\n",
    "\n",
    "\n",
    "BASE = getSystemRoot()\n",
    "USER_PROFILE_TERM_FREQ_FILEPATH = '%s/Desktop/TEMPORARY/user-profile-word-counts.csv' % BASE\n",
    "MIN_100_NO_STOPS = '/Users/adam/Desktop/TEMPORARY/user-profile-word-counts-min-100-ex-stops.csv'\n",
    "MAP_PICKLE_PATH = '%s/Desktop/TEMPORARY/user-id-map' % BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:38.468463Z",
     "start_time": "2018-04-06T23:17:38.464717Z"
    }
   },
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "# The minimum frequency above which to\n",
    "# exclude terms\n",
    "MIN_FREQ = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create cursor for user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:38.671167Z",
     "start_time": "2018-04-06T23:17:38.471515Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd twitteranalysis\n",
    "%run -i DataTools/Cursors\n",
    "# from DataTools.Cursors import UserCursor\n",
    "u = UserCursor(language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:38.995818Z",
     "start_time": "2018-04-06T23:17:38.673657Z"
    }
   },
   "outputs": [],
   "source": [
    "user = u.next()\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.007411Z",
     "start_time": "2018-04-06T23:17:38.998379Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd twitteranalysis\n",
    "%run -i DataTools/Cursors\n",
    "\n",
    "u = WindowedUserCursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T00:06:01.344576Z",
     "start_time": "2018-03-31T00:06:01.336054Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.048295Z",
     "start_time": "2018-04-06T23:17:39.009763Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd twitteranalysis\n",
    "%run -i DataTools/TweetORM\n",
    "\n",
    "def userIter():\n",
    "    maxrq = 2\n",
    "    firstid = None\n",
    "    pk_attr = DataTools.TweetORM.Users.userID\n",
    "    qry = u.dao.session.query(DataTools.TweetORM.Users)\n",
    "    q = qry\n",
    "#     for i in range(0, 2):\n",
    "#     while True:\n",
    "    rec = None\n",
    "    if firstid is not None:\n",
    "        q = qry.filter(DataTools.TweetORM.Users.userID > firstid)\n",
    "        \n",
    "        for rec in q.order_by(DataTools.TweetORM.Users.userID).limit(maxrq):\n",
    "            yield rec\n",
    "        if rec is None:\n",
    "            raise StopIteration\n",
    "        # after iteration is complete\n",
    "        # set the start id to the last retrieved record's id\n",
    "    firstid = pk_attr.__get__(rec, pk_attr) if rec else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.054521Z",
     "start_time": "2018-04-06T23:17:39.050964Z"
    }
   },
   "outputs": [],
   "source": [
    "maxid = 531"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.084535Z",
     "start_time": "2018-04-06T23:17:39.057165Z"
    }
   },
   "outputs": [],
   "source": [
    "class J:\n",
    "    def __init__(self, dao):\n",
    "        self.firstId = 0\n",
    "        self.limit = 4\n",
    "        self.pk_attr = DataTools.TweetORM.Users.userID\n",
    "        self.qry = dao.session.query(DataTools.TweetORM.Users)\n",
    "        self.my_iter = self.a()\n",
    "    \n",
    "    def next(self):\n",
    "        return next(self.my_iter)\n",
    "        \n",
    "    def a(self):\n",
    "        \n",
    "        while True:\n",
    "            q = qry\n",
    "            if self.firstId is not None:\n",
    "                # get records with ids higher than our highest current\n",
    "                q = qry.filter(self.pk_attr > self.firstId)\n",
    "            rec = None\n",
    "            for rec in q.order_by(self.pk_attr).limit(self.limit):\n",
    "                yield rec\n",
    "            if rec is None:\n",
    "                break\n",
    "            self.firstId = self.pk_attr.__get__(rec, self.pk_attr) if rec else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.095135Z",
     "start_time": "2018-04-06T23:17:39.087673Z"
    }
   },
   "outputs": [],
   "source": [
    "j = J(u.dao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.109294Z",
     "start_time": "2018-04-06T23:17:39.097971Z"
    }
   },
   "outputs": [],
   "source": [
    "uss = u.next()\n",
    "uss.userID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.343401Z",
     "start_time": "2018-04-06T23:17:39.112070Z"
    }
   },
   "outputs": [],
   "source": [
    "n = j.itt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.344731Z",
     "start_time": "2018-04-06T23:17:37.574Z"
    }
   },
   "outputs": [],
   "source": [
    "next(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.346209Z",
     "start_time": "2018-04-06T23:17:37.578Z"
    }
   },
   "outputs": [],
   "source": [
    "itt.maxid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.348047Z",
     "start_time": "2018-04-06T23:17:37.580Z"
    }
   },
   "outputs": [],
   "source": [
    "ui = userIter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.350116Z",
     "start_time": "2018-04-06T23:17:37.584Z"
    }
   },
   "outputs": [],
   "source": [
    "next(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.352042Z",
     "start_time": "2018-04-06T23:17:37.590Z"
    }
   },
   "outputs": [],
   "source": [
    "q = q.filter(DataTools.TweetORM.Users.userID > 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.353772Z",
     "start_time": "2018-04-06T23:17:37.594Z"
    }
   },
   "outputs": [],
   "source": [
    "for rec in q.order_by(pk_attr).limit(2):\n",
    "    firstid = pk_attr.__get__(rec, pk_attr) if rec else None\n",
    "    print(firstid)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:58:09.633963Z",
     "start_time": "2018-04-11T00:58:09.449004Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reset database\n",
    "%cd twitteranalysis\n",
    "from DataTools.WordORM import create_db_tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T00:58:16.603424Z",
     "start_time": "2018-04-11T00:58:16.390536Z"
    }
   },
   "outputs": [],
   "source": [
    "create_db_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Windowing user cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.355485Z",
     "start_time": "2018-04-06T23:17:37.674Z"
    }
   },
   "outputs": [],
   "source": [
    "next(u.item_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.357209Z",
     "start_time": "2018-04-06T23:17:37.678Z"
    }
   },
   "outputs": [],
   "source": [
    "j = u.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.359089Z",
     "start_time": "2018-04-06T23:17:37.682Z"
    }
   },
   "outputs": [],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-17T03:35:06.922547Z",
     "start_time": "2018-02-17T03:35:06.919557Z"
    }
   },
   "source": [
    "# Word counts in user descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.360718Z",
     "start_time": "2018-04-06T23:17:37.738Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd texttools\n",
    "from TextProcessors.Filters import *\n",
    "from TextProcessors.Modifiers import *\n",
    "from TextProcessors.Processors import *\n",
    "\n",
    "filters = [\n",
    "     UsernameFilter(),\n",
    "    PunctuationFilter(),\n",
    "    URLFilter(),\n",
    "    NumeralFilter()\n",
    "]\n",
    "\n",
    "modifiers = [\n",
    "    WierdBPrefixConverter(), \n",
    "    CaseConverter( ) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.362196Z",
     "start_time": "2018-04-06T23:17:37.744Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd texttools\n",
    "%run -i StatisticalTools/Counters\n",
    "counter = WordCounter()\n",
    "counter.add_filters(filters)\n",
    "counter.add_modifiers(modifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T23:08:15.824113Z",
     "start_time": "2018-03-23T23:08:15.820202Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating with older tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.364056Z",
     "start_time": "2018-04-06T23:17:37.832Z"
    }
   },
   "outputs": [],
   "source": [
    "# Statistical tools approach is better, but\n",
    "# older version separates work better...\n",
    "\n",
    "%cd twitteranalysis\n",
    "%run -i ProcessingTools/QueueTools.py\n",
    "%run -i ProcessingTools/ProcessingControllers.py\n",
    "%run -i ProcessingTools/Listeners.py\n",
    "\n",
    "# First set up the object which will handle applying\n",
    "# filters and modifiers to each word\n",
    "word_processor = SingleWordProcessor()\n",
    "word_processor.add_filters(filters)\n",
    "word_processor.add_modifiers(modifiers)\n",
    "\n",
    "# Set up the machinery for saving the \n",
    "# processed results\n",
    "queueHandler = SaveQueueHandler()\n",
    "listener = SaveListener()\n",
    "queueHandler.register_listener(listener)\n",
    "\n",
    "# Finally create the command and control\n",
    "control = UserProcessingController(queueHandler)\n",
    "control.load_word_processor(word_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.366039Z",
     "start_time": "2018-04-06T23:17:37.834Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd twitteranalysis\n",
    "\n",
    "# Make a fake user\n",
    "%run -i TestingTools/Factories.py\n",
    "%run -i TestingTools/DummyCursors.py\n",
    "dummyCursor =DummyUserCursor()\n",
    "# user = UserFactory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.367588Z",
     "start_time": "2018-04-06T23:17:37.840Z"
    }
   },
   "outputs": [],
   "source": [
    "Faker().word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.369382Z",
     "start_time": "2018-04-06T23:17:37.844Z"
    }
   },
   "outputs": [],
   "source": [
    "t =TweetResultFactory()\n",
    "t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.370966Z",
     "start_time": "2018-04-06T23:17:37.848Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.randint(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.373192Z",
     "start_time": "2018-04-06T23:17:37.854Z"
    }
   },
   "outputs": [],
   "source": [
    "u = dummyCursor.next()\n",
    "u.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.375236Z",
     "start_time": "2018-04-06T23:17:37.858Z"
    }
   },
   "outputs": [],
   "source": [
    "def _yield_limit(qry, pk_attr, maxrq=100):\n",
    "    \"\"\"specialized windowed query generator (using LIMIT/OFFSET)\n",
    "\n",
    "    This recipe is to select through a large number of rows thats too\n",
    "    large to fetch at once. The technique depends on the primary key\n",
    "    of the FROM clause being an integer value, and selects items\n",
    "    using LIMIT.\"\"\"\n",
    "\n",
    "    firstid = None\n",
    "    while True:\n",
    "        q = qry\n",
    "        if firstid is not None:\n",
    "            q = qry.filter(pk_attr > firstid)\n",
    "        rec = None\n",
    "        for rec in q.order_by(pk_attr).limit(maxrq):\n",
    "            yield rec\n",
    "        if rec is None:\n",
    "            break\n",
    "        firstid = pk_attr.__get__(rec, pk_attr) if rec else None\n",
    "\n",
    "from sqlalchemy import create_engine, Column, Integer\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class A(Base):\n",
    "    __tablename__ = 'a'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "\n",
    "e = create_engine(\"sqlite://\", echo=True)\n",
    "Base.metadata.create_all(e)\n",
    "\n",
    "sess = Session(e)\n",
    "\n",
    "sess.add_all([A() for i in range(2000)])\n",
    "\n",
    "for rec in _yield_limit(sess.query(A), A.id):\n",
    "    print(rec.id, rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlining db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T19:05:07.910489Z",
     "start_time": "2018-04-12T19:05:07.906846Z"
    }
   },
   "outputs": [],
   "source": [
    "DB_HOST = '127.0.0.1'\n",
    "DB_NAME = 'twitter_wordsTEST'\n",
    "DB_USER = 'root'\n",
    "DB_PASS = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T20:54:55.377126Z",
     "start_time": "2018-04-12T20:54:55.365484Z"
    }
   },
   "outputs": [],
   "source": [
    "import MySQLdb as msq\n",
    "import MySQLdb.cursors\n",
    "\n",
    "\n",
    "class NonAutocommittingBaseDAO:\n",
    "    \"\"\"\n",
    "    Base data access object. \n",
    "    Inherited by all classes that need to access the mysql database\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__( self, batchSize=100 ):\n",
    "        self.mysqlError = MySQLdb.Error\n",
    "        self.batchSize= batchSize\n",
    "        self.cnt = 0\n",
    "        \n",
    "        try:\n",
    "\n",
    "            self.db = msq.connect( DB_HOST, DB_USER, DB_PASS, DB_NAME,\n",
    "                                   cursorclass=MySQLdb.cursors.DictCursor )\n",
    "            self.db.autocommit( False )\n",
    "            self.dbc = self.db.cursor()\n",
    "            print( 'connected to: ', DB_NAME )\n",
    "        except MySQLdb.Error as e:\n",
    "            print( \"Connection error: %s \" % e )\n",
    "\n",
    "    def check_flush(self):\n",
    "        if self.batchSize <= self.cnt:\n",
    "            self.db.commit()\n",
    "            self.cnt = 0\n",
    "            print('committed', self.cnt)\n",
    "        \n",
    "\n",
    "    def executeQuery( self, query, val ):\n",
    "        \"\"\"\n",
    "        Prepares and executes the query stored in self.query with the variables in self.val\n",
    "        Usually used for insert, update, and other functions which don't require a return\n",
    "        \"\"\"\n",
    "        if type(val) is not tuple:\n",
    "            val = (val,)\n",
    "            \n",
    "        try:\n",
    "            self.dbc.execute( query, val )\n",
    "            self.cnt += 1\n",
    "            self.check_flush()\n",
    "\n",
    "        except MySQLdb.Error as e:\n",
    "            self.handleError(e)\n",
    "\n",
    "\n",
    "    def returnOne( self, query, val ):\n",
    "        \"\"\"\n",
    "        Executes the query stored in self.query with the vals in self.val.\n",
    "        Returns the first row in an array called self.results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.dbc.execute( query, val )\n",
    "            self.results = self.dbc.fetchone()\n",
    "        except MySQLdb.Error as e:\n",
    "            self.handleError(e)\n",
    "\n",
    "    def handleError(self, error):\n",
    "        print( \"Query failed: %s \" % error )\n",
    "\n",
    "\n",
    "    def returnAll( self, query, val ):\n",
    "        \"\"\"\n",
    "        Executes the query stored in self.query with the vals in self.val.\n",
    "        Return the results in an array called self.results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.dbc.execute( query, val )\n",
    "            self.results = self.dbc.fetchall()\n",
    "        except MySQLdb.Error as e:\n",
    "            self.handleError(e)\n",
    "        \n",
    "\n",
    "class WordDAO(NonAutocommittingBaseDAO):\n",
    "    def __init__(self, batchsize=100):\n",
    "        super().__init__(batchsize)\n",
    "    \n",
    "    def get_word_id(self, word):\n",
    "        \"\"\"Returns the id of the word if it already exists\"\"\"\n",
    "        try:\n",
    "            self.executeQuery(\"\"\"SELECT id FROM words WHERE word = %s\"\"\", word)\n",
    "            r = self.dbc.fetchone()\n",
    "            return r['id']\n",
    "        except:\n",
    "            return self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        \"\"\"\n",
    "        Adds a new word to the words table\n",
    "        Will return the id of the newly inserted word\n",
    "        \"\"\"\n",
    "        q = \"\"\"INSERT INTO words (word) VALUES (%s)\"\"\"\n",
    "        self.executeQuery(q, word)\n",
    "        self.db.commit()\n",
    "        self.dbc.execute(\"\"\"SELECT LAST_INSERT_ID() AS id\"\"\")\n",
    "        r = self.dbc.fetchone()\n",
    "        return r['id']\n",
    "\n",
    "class WordMapDAO(NonAutocommittingBaseDAO):\n",
    "    \n",
    "    def __init__(self, batchsize=100):\n",
    "        super().__init__(batchsize)\n",
    "\n",
    "    \n",
    "    def add(self, wordId, sentenceIndex, wordIndex, tweetId=None, userId=None):\n",
    "        tweetQuery = \"\"\"INSERT INTO word_map (word_id, sentence_index, word_index, tweet_id) \n",
    "            VALUES (%s, %s, %s, %s)\"\"\"\n",
    "        \n",
    "        userQuery = \"\"\"INSERT INTO word_map (word_id, sentence_index, word_index, user_id) \n",
    "            VALUES (%s, %s, %s, %s)\"\"\"\n",
    "        \n",
    "        if tweetId is not None: \n",
    "            q = tweetQuery\n",
    "            oid = tweetId\n",
    "            \n",
    "        if userId is not None:\n",
    "            q = userQuery\n",
    "            oid = userId\n",
    "            \n",
    "        return self.executeQuery(q, (wordId, sentenceIndex, wordIndex, oid))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T20:54:56.872651Z",
     "start_time": "2018-04-12T20:54:56.829475Z"
    }
   },
   "outputs": [],
   "source": [
    "wd = WordDAO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T20:54:58.712015Z",
     "start_time": "2018-04-12T20:54:58.694367Z"
    }
   },
   "outputs": [],
   "source": [
    "wd.get_word_id('kjhkhkhkhhhhhh23saa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T20:15:16.739739Z",
     "start_time": "2018-04-12T20:15:16.728158Z"
    }
   },
   "outputs": [],
   "source": [
    "k = wd.add_word('faljer')\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T20:15:17.640591Z",
     "start_time": "2018-04-12T20:15:17.628409Z"
    }
   },
   "outputs": [],
   "source": [
    "wd.add_word('faljer2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T19:15:44.626887Z",
     "start_time": "2018-04-12T19:15:44.623235Z"
    }
   },
   "outputs": [],
   "source": [
    "d.db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on async queuing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.376812Z",
     "start_time": "2018-04-06T23:17:37.956Z"
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "from time import sleep\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.378528Z",
     "start_time": "2018-04-06T23:17:37.958Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@asyncio.coroutine \n",
    "def foo():\n",
    "    print('Running in foo')\n",
    "    yield from asyncio.sleep(0)\n",
    "    print('Explicit context switch to foo again')\n",
    "\n",
    "@asyncio.coroutine \n",
    "def bar():\n",
    "    print('Explicit context to bar')\n",
    "    yield from asyncio.sleep(0)\n",
    "    print('Implicit context switch back to bar')\n",
    "\n",
    "\n",
    "ioloop = asyncio.get_event_loop()\n",
    "tasks = [ioloop.create_task(foo()), ioloop.create_task(bar())]\n",
    "wait_tasks = asyncio.wait(tasks)\n",
    "ioloop.run_until_complete(wait_tasks)\n",
    "ioloop.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.380255Z",
     "start_time": "2018-04-06T23:17:37.962Z"
    }
   },
   "outputs": [],
   "source": [
    "def task(pid):\n",
    "    \"\"\"Synchronous non-deterministic task.\n",
    "    \"\"\"\n",
    "    sleep(random.randint(0, 2) * 0.001)\n",
    "    print('Task %s done' % pid)\n",
    "\n",
    "@asyncio.coroutine\n",
    "def task_coro(pid):\n",
    "    \"\"\"Coroutine non-deterministic task\n",
    "    \"\"\"\n",
    "    yield from asyncio.sleep(random.randint(0, 2) * 0.001)\n",
    "    print('Task %s done' % pid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.381899Z",
     "start_time": "2018-04-06T23:17:37.966Z"
    }
   },
   "outputs": [],
   "source": [
    "ioloop = asyncio.get_event_loop()\n",
    "result_queue = []\n",
    "\n",
    "def enqueue(result):\n",
    "    result_queue.append(ioloop.create_task(save_to_db(result)))\n",
    "\n",
    "def handle_queue():\n",
    "    wait_tasks = asyncio.wait(result_queue)\n",
    "    ioloop.run_until_complete(wait_tasks)\n",
    "    \n",
    "@asyncio.coroutine \n",
    "def save_to_db(result):\n",
    "    print(\"I'm saving %s to db\" % result)\n",
    "    \n",
    "\n",
    "for i in range(0, 10):\n",
    "    enqueue(i)\n",
    "    handle_queue()\n",
    "    if i == 10: ioloop.close()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#     loop = asyncio.get_event_loop()\n",
    "#     try:\n",
    "#         loop.call_soon(functools.partial\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the most basic definitions of asyncio main concepts:\n",
    "\n",
    "Coroutine \n",
    "\n",
    "— generator that consumes data, but doesn’t generate it. Python 2.5 introduced a new syntax that made it possible to send a value to a generator. I recommend checking David Beazley’s “A Curious Course on Coroutines and Concurrency” for a detailed description of coroutines.\n",
    "    \n",
    "    \n",
    "Tasks \n",
    "\n",
    "— schedulers for coroutines. If you check a source code below, you’ll see that it just says event_loop to run its _step as soon as possible, meanwhile _step just calls next step of coroutine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.383773Z",
     "start_time": "2018-04-06T23:17:38.050Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import asyncio  \n",
    "import time  \n",
    "from datetime import datetime\n",
    "\n",
    "class Task(asyncio.futures.Future):  \n",
    "    def __init__(self, coro, loop=None):\n",
    "        super().__init__(loop=loop)\n",
    "#         ...\n",
    "        self._loop.call_soon(self._step)\n",
    "\n",
    "    def _step(self):\n",
    "#             ...\n",
    "        try:\n",
    "#             ...\n",
    "            result = next(self._coro)\n",
    "        except StopIteration as exc:\n",
    "            self.set_result(exc.value)\n",
    "        except BaseException as exc:\n",
    "            self.set_exception(exc)\n",
    "            raise\n",
    "        else:\n",
    "#             ...\n",
    "            self._loop.call_soon(self._step)\n",
    "\n",
    "@asyncio.coroutine\n",
    "def custom_sleep():  \n",
    "    print('SLEEP', datetime.now())\n",
    "    yield from asyncio.sleep(1)\n",
    "#     time.sleep(1)\n",
    "\n",
    "@asyncio.coroutine\n",
    "def factorial(name, number):  \n",
    "    f = 1\n",
    "    for i in range(2, number+1):\n",
    "        print('Task {}: Compute factorial({})'.format(name, i))\n",
    "        yield from custom_sleep()\n",
    "        f *= i\n",
    "    print('Task {}: factorial({}) is {}\\n'.format(name, number, f))\n",
    "\n",
    "start = time.time()  \n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "tasks = [  \n",
    "    factorial(\"A\", 3),\n",
    "    factorial(\"B\", 4),\n",
    "]\n",
    "loop.run_until_complete(asyncio.wait(tasks))  \n",
    "loop.close()\n",
    "\n",
    "end = time.time()  \n",
    "print(\"Total time: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.385473Z",
     "start_time": "2018-04-06T23:17:38.054Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import asyncio\n",
    "\n",
    "@asyncio.coroutine\n",
    "def my_task(seconds):\n",
    "    \"\"\"\n",
    "    A task to do for a number of seconds\n",
    "    \"\"\"\n",
    "    print('This task is taking {} seconds to complete'.format(seconds))\n",
    "    yield from asyncio.sleep(seconds)\n",
    "    return 'task finished'\n",
    " \n",
    "def run():\n",
    "    my_event_loop = asyncio.get_event_loop()\n",
    "    try:\n",
    "        print('task creation started')\n",
    "        task_obj = my_event_loop.create_task(my_task(seconds=2))\n",
    "        my_event_loop.run_until_complete(task_obj)\n",
    "    finally:\n",
    "        my_event_loop.close()\n",
    "        print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.386945Z",
     "start_time": "2018-04-06T23:17:38.058Z"
    }
   },
   "outputs": [],
   "source": [
    "run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.388449Z",
     "start_time": "2018-04-06T23:17:38.064Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import izip\n",
    "\n",
    "def finish_save(response, result):\n",
    "    if response.code != 200:\n",
    "        print \"Error saving prime: {}\".format(prime)\n",
    "\n",
    "def do_thing(t):\n",
    "    pass\n",
    "\n",
    "class AsyncBatcher(object):\n",
    "    __slots__ = [\"batch\", \"batch_size\", \"save\", \"flush\"] def __init__(self, batch_size):\n",
    "    self.batch_size = batch_size\n",
    "    self.batch = []\n",
    "\n",
    "    def save(self, result):\n",
    "        url = \"bzzzzrrrrrppp saaaaavvvvviiiinnngggg\"\n",
    "        self.batch.append((url,result))\n",
    "        if len(self.batch) == self.batch_size:\n",
    "            self.flush()\n",
    "\n",
    "def flush(self):\n",
    "    responses_futures = (do_thing(url) for url, _ in self.batch) \n",
    "    responses = grequests.map(responses_futures)\n",
    "    for response, (url, result) in izip(responses, self.batch):\n",
    "        finish_save(response, result)\n",
    "    self.batch = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T01:29:33.152677Z",
     "start_time": "2018-03-28T01:29:33.149691Z"
    }
   },
   "source": [
    "# Tornado "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.391424Z",
     "start_time": "2018-04-06T23:17:38.270Z"
    }
   },
   "outputs": [],
   "source": [
    "# send result to db server to be recorded\n",
    "\n",
    "%cd twitteranalysis\n",
    "import environment\n",
    "url = environment.DB_URL\n",
    "\n",
    "%run -i Servers/Helpers.py\n",
    "%run -i Servers/ClientSide.py\n",
    "%run -i TestingTools/Factories.py\n",
    "\n",
    "# from tornado.httpclient import AsyncHTTPClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.392953Z",
     "start_time": "2018-04-06T23:17:38.276Z"
    }
   },
   "outputs": [],
   "source": [
    "# payload = UserResultFactory()\n",
    "        \n",
    "# http_client = AsyncHTTPClient() \n",
    "\n",
    "# send_result(http_client, url, payload)\n",
    "\n",
    "# http_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.394439Z",
     "start_time": "2018-04-06T23:17:38.280Z"
    }
   },
   "outputs": [],
   "source": [
    "# tornado logging\n",
    "access_log = logging.getLogger(\"tornado.access\")\n",
    "app_log = logging.getLogger(\"tornado.application\")\n",
    "gen_log = logging.getLogger(\"tornado.general\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T02:23:19.150265Z",
     "start_time": "2018-04-20T02:23:19.078845Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# Create new log\n",
    "%cd ~/Desktop/TwitterDataAnalysisLogs\n",
    "%sx rm query_time_log.csv\n",
    "%sx touch query_time_log.csv\n",
    "%sx rm query_log.csv\n",
    "%sx touch query_log.csv\n",
    "%sx rm wordmapping.db\n",
    "%sx touch wordmapping.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To audit:\n",
    "Before running, execute in db: \n",
    "    \n",
    "    DELETE FROM word_map; DELETE FROM words\n",
    "\n",
    "After run, compare count of users to \n",
    "\n",
    "SELECT count( DISTINCT user_id) FROM word_map;\n",
    "\n",
    "SELECT count( DISTINCT userID) FROM users;\n",
    "    \n",
    "332 have blank profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T02:50:59.736256Z",
     "start_time": "2018-04-20T02:50:42.498935Z"
    },
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T02:23:38.784330Z",
     "start_time": "2018-04-20T02:23:38.778944Z"
    }
   },
   "outputs": [],
   "source": [
    "# check stored sqlite file\n",
    "%cd twitteranalysis\n",
    "import sqlite3\n",
    "import environment\n",
    "\n",
    "f = environment.SQLITE_FILE\n",
    "\n",
    "conn = sqlite3.connect(f)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T01:45:53.176814Z",
     "start_time": "2018-04-18T01:45:53.173576Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "r = cursor.execute('SELECT count(word) FROM word_map_deux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T01:45:53.458592Z",
     "start_time": "2018-04-18T01:45:53.454740Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in r:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQlite 4.17.18\n",
    "4352 users processed (not nec done)\n",
    "\n",
    "67943 responses\n",
    "\n",
    "4352 profiles (of 4353) took 15.318603992462158 seconds. That's 0.00351989981444443 seconds per profile\n",
    "\n",
    "db done after 3min 31 sec; recorded 43784 (1.1mb)\n",
    "\n",
    "mysql 4.17\n",
    "4352 users processed (not nec done)\n",
    "67943 responses\n",
    "4352 profiles (of 4353) took 15.312575101852417 seconds. That's 0.00351851449950653 seconds per profile\n",
    "\n",
    "db done after ~4 min (3.5mb); recorded 67943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T02:47:24.211641Z",
     "start_time": "2018-04-18T02:47:24.205635Z"
    }
   },
   "outputs": [],
   "source": [
    "numberUsersProcessed = 4352\n",
    "totalUsers = 1328927\n",
    "\n",
    "secPerUser = numberUsersProcessed / (4*60)\n",
    "estSec = totalUsers * secPerUser\n",
    "print(\"estimated time: %s seconds\" % estSec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T02:48:19.985202Z",
     "start_time": "2018-04-18T02:48:19.979391Z"
    }
   },
   "outputs": [],
   "source": [
    "estHours = (estSec / 60) / 60\n",
    "estHours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-13T01:39:11.077318Z",
     "start_time": "2018-04-13T01:39:11.034806Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd twitteranalysis\n",
    "\n",
    "from DataTools import DataConnections\n",
    "from DataTools import WordORM\n",
    "ENGINE = 'sqlite'\n",
    "            \n",
    "engine = DataConnections.initialize_engine()\n",
    "WordORM.create_db_tables(engine)\n",
    "# DataTools's handle to database at global level\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-13T01:22:22.036897Z",
     "start_time": "2018-04-13T01:22:22.004751Z"
    }
   },
   "outputs": [],
   "source": [
    "engine.execute(\"select * from words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.407828Z",
     "start_time": "2018-04-06T23:17:38.464Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(control.responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.409316Z",
     "start_time": "2018-04-06T23:17:38.470Z"
    }
   },
   "outputs": [],
   "source": [
    "control.prune_responses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.410751Z",
     "start_time": "2018-04-06T23:17:38.478Z"
    }
   },
   "outputs": [],
   "source": [
    "payload = UserResultFactory()\n",
    "\n",
    "client = Client()\n",
    "f = client.send(payload)\n",
    "f.done()\n",
    "# client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.412417Z",
     "start_time": "2018-04-06T23:17:38.482Z"
    }
   },
   "outputs": [],
   "source": [
    "f.done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.414789Z",
     "start_time": "2018-04-06T23:17:38.486Z"
    }
   },
   "outputs": [],
   "source": [
    "client.http_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.416141Z",
     "start_time": "2018-04-06T23:17:38.492Z"
    }
   },
   "outputs": [],
   "source": [
    "DB_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redis as word id lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T03:37:07.665112Z",
     "start_time": "2018-04-11T03:37:07.654016Z"
    }
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "\n",
    "class RedisDAO(object):\n",
    "    \"\"\"\n",
    "    Creates connection to redis host. \n",
    "    Base class for redis services. Should not be directly called.\n",
    "\n",
    "    Attributes:\n",
    "        dbindex: Default 'db0'\n",
    "        db: redis.Redis connection\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, host='localhost', port=6379, db=0):\n",
    "        d = str(db)\n",
    "        #self.dbindex = 0\n",
    "        self.dbindex = 'db%s' % d\n",
    "        self.db = redis.Redis(host=host, port=port, db=db)\n",
    "\n",
    "    def delete_all_databases(self):\n",
    "        self.flushall()\n",
    "#         pass\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def save_tweet_id_to_master_list(self, tweetid):\n",
    "        self.setname = 'tweetIDs'\n",
    "        try:\n",
    "            tid = 'unique_tweets:tweet_id:%s' % tweetid\n",
    "            self.db.sadd(tid, tid)\n",
    "        except Exception as e:\n",
    "            print \"error %s\" % e\n",
    "\n",
    "    def save_tweet_id(self, tweetid):\n",
    "        \"\"\"\n",
    "        @param tweetid This is the id to be recorded in redis\n",
    "        @type tweetid Number or string\n",
    "        \"\"\"\n",
    "        # Name of the set that will be storing all the data\n",
    "        self.setname = 'tweetIDs'\n",
    "        try:\n",
    "            #tid = 'unique_tweets:tweet_id:%s' % tweetid\n",
    "            self.db.sadd(self.setname, tweetid)\n",
    "        except Exception as e:\n",
    "            print \"error %s\" % e\n",
    "\n",
    "    def get_max_id(self):\n",
    "        try:\n",
    "            self.maxid = self.db.sort('tweetIDs', start=0, num=1, desc=True)\n",
    "            return self.maxid\n",
    "            # self.loadkeys()\n",
    "            # mx = max(self.keys)\n",
    "            # self.maxid = RedisFormat.tweet_id_remove(mx)\n",
    "        except Exception as e:\n",
    "            print \"Error: %s \" % e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.417452Z",
     "start_time": "2018-04-06T23:17:38.520Z"
    }
   },
   "outputs": [],
   "source": [
    "Us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.418909Z",
     "start_time": "2018-04-06T23:17:38.528Z"
    }
   },
   "outputs": [],
   "source": [
    "user = u.next()\n",
    "user.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.420512Z",
     "start_time": "2018-04-06T23:17:38.536Z"
    }
   },
   "outputs": [],
   "source": [
    "control.process(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.422054Z",
     "start_time": "2018-04-06T23:17:38.542Z"
    }
   },
   "outputs": [],
   "source": [
    "queueHandler.queue.queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.423804Z",
     "start_time": "2018-04-06T23:17:38.548Z"
    }
   },
   "outputs": [],
   "source": [
    "# This model works faster\n",
    "us = []\n",
    "for i in range(0, 20):\n",
    "    us.append(u.next())\n",
    "\n",
    "[ control.process(u) for u in us]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.425570Z",
     "start_time": "2018-04-06T23:17:38.554Z"
    }
   },
   "outputs": [],
   "source": [
    "# Next task: getting the queueHandler to do its job\n",
    "# and save to sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T23:16:32.928246Z",
     "start_time": "2018-03-23T23:16:32.911525Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the user descriptions for word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.427274Z",
     "start_time": "2018-04-06T23:17:38.748Z"
    }
   },
   "outputs": [],
   "source": [
    "# Don't know why but this is incredibly slow\n",
    "# restricted number of users for testing\n",
    "# max_users = 2\n",
    "\n",
    "# for i in range(0, max_users):\n",
    "#     user = u.next()\n",
    "#     upc.process(user)\n",
    "# #     counter.process(user.description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.428793Z",
     "start_time": "2018-04-06T23:17:38.756Z"
    }
   },
   "outputs": [],
   "source": [
    "sq.queue.queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-10T06:41:46.749010Z",
     "start_time": "2018-03-10T06:35:15.290238Z"
    },
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_word_freq_in_user_profiles(counter, userCursor):\n",
    "    # all users\n",
    "    user_count = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user = userCursor.next()\n",
    "    #         Note that we're not going to add the id to the map yet\n",
    "            counter.process(user.description)\n",
    "            user_count += 1\n",
    "        except StopIteration as e:\n",
    "            print(\"%s users processed; %s words identified\" % (user_count, len(counter.counts)))\n",
    "            break\n",
    "\n",
    "    return Series(counter.counts)\n",
    "\n",
    "# word_freq_in_user_profiles = process_word_freq_in_user_profiles(counter, u)\n",
    "# word_freq_in_user_profiles.to_csv(USER_PROFILE_TERM_FREQ_FILEPATH)\n",
    "\n",
    "# took 6m31s to process \n",
    "# 1162362 users processed; 846948 words identified\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report word frequencies in user profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.430564Z",
     "start_time": "2018-04-06T23:17:38.926Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "word_freq_in_user_profiles.hist(ax=ax, bins=100, bottom=0.1)\n",
    "ax.set_yscale('log')\n",
    "ax.set_title(\"Term frequency in user profiles\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncate the found word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.432142Z",
     "start_time": "2018-04-06T23:17:39.132Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove terms \n",
    "words = word_freq_in_user_profiles.loc[lambda x: x > MIN_FREQ]\n",
    "print(\"%s words out of %s appear more often than %sx\" % (len(words), len(word_freq_in_user_profiles), MIN_FREQ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.433455Z",
     "start_time": "2018-04-06T23:17:39.138Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "out = '/Users/adam/Desktop/TEMPORARY/user-profile-word-counts-over-100.csv'\n",
    "# words.to_csv(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.434797Z",
     "start_time": "2018-04-06T23:17:39.144Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "words.hist(ax=ax, bins=100, bottom=0.1)\n",
    "ax.set_yscale('log')\n",
    "ax.set_title(\"Term frequency in user profiles (min: %s)\" % MIN_FREQ)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.436373Z",
     "start_time": "2018-04-06T23:17:39.370Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_stopword(text):\n",
    "    \"\"\"check whether the supplied text is a stopword\"\"\"\n",
    "    return text in nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(series):\n",
    "    d = {}\n",
    "    for k in series.keys():\n",
    "        if not is_stopword(k):\n",
    "             d[k] = series[k]\n",
    "    print(\"Removed %s stopwords from the words list\" % (len(series) - len(d.keys())))\n",
    "    return Series(d)\n",
    "\n",
    "words = remove_stopwords(words)\n",
    "#words.to_csv(MIN_100_NO_STOPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T03:52:58.679342Z",
     "start_time": "2018-03-14T03:52:58.676336Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word frequencies in user profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:39.624771Z",
     "start_time": "2018-04-06T23:17:39.611435Z"
    }
   },
   "outputs": [],
   "source": [
    "words = pd.read_csv(MIN_100_NO_STOPS, header=None, names=['term', 'freq'])\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:40.569229Z",
     "start_time": "2018-04-06T23:17:39.627234Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "words.freq.hist(ax=ax, bins=100, bottom=0.1)\n",
    "ax.set_yscale('log')\n",
    "ax.set_title(\"User profile term freq (min: %s ; stopwords removed)\" % MIN_FREQ)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:40.962843Z",
     "start_time": "2018-04-06T23:17:40.571478Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "sns.distplot(words.freq, ax=ax)\n",
    "ax.set_title(\"KDE of Term frequency in user profiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:40.976154Z",
     "start_time": "2018-04-06T23:17:40.965969Z"
    }
   },
   "outputs": [],
   "source": [
    "words.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.000939Z",
     "start_time": "2018-04-06T23:17:40.979302Z"
    }
   },
   "outputs": [],
   "source": [
    "w = words.sort_values(by='freq', ascending=False)\n",
    "w[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.016807Z",
     "start_time": "2018-04-06T23:17:41.003611Z"
    }
   },
   "outputs": [],
   "source": [
    "j = pd.read_csv(MIN_100_NO_STOPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.026395Z",
     "start_time": "2018-04-06T23:17:41.019608Z"
    }
   },
   "outputs": [],
   "source": [
    "len(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.044950Z",
     "start_time": "2018-04-06T23:17:41.029064Z"
    }
   },
   "outputs": [],
   "source": [
    "ww = words.copy(deep=True)[:10]\n",
    "w5 = ww.loc[lambda x : x.freq > 1000]\n",
    "w5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.060696Z",
     "start_time": "2018-04-06T23:17:41.047521Z"
    }
   },
   "outputs": [],
   "source": [
    "j[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.071090Z",
     "start_time": "2018-04-06T23:17:41.063538Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove terms \n",
    "def filter_freq_list_by_min(wordFrame, minFreq):\n",
    "    \"\"\"Returns a copy of the frame, sans terms which do not occur above the minimum frequency\"\"\"\n",
    "    w = wordFrame.loc[lambda x: x.freq > minFreq]\n",
    "    print(\"%s words out of %s appear more often than %sx\" % (len(w), len(wordFrame), minFreq))\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.083101Z",
     "start_time": "2018-04-06T23:17:41.073809Z"
    }
   },
   "outputs": [],
   "source": [
    "w4 = filter_freq_list_by_min(words, 10000)\n",
    "len(w4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.121137Z",
     "start_time": "2018-04-06T23:17:41.085805Z"
    }
   },
   "outputs": [],
   "source": [
    "w4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.158717Z",
     "start_time": "2018-04-06T23:17:41.124774Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd texttools\n",
    "%run -i StatisticalTools/Counters\n",
    "selectedCounter = SelectedWordCounter()\n",
    "selectedCounter.set_words_to_count(list(counter.map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.161129Z",
     "start_time": "2018-04-06T23:17:39.708Z"
    }
   },
   "outputs": [],
   "source": [
    "selectedCounter.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.164009Z",
     "start_time": "2018-04-06T23:17:39.714Z"
    }
   },
   "outputs": [],
   "source": [
    "# restricted number of users for testing\n",
    "max_users = 10\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, max_users):\n",
    "    user = u.next()\n",
    "    selectedCounter.process(user.description, user.userID)\n",
    "\n",
    "    \n",
    "# todo save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.166622Z",
     "start_time": "2018-04-06T23:17:39.722Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "selectedCounter.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.170319Z",
     "start_time": "2018-04-06T23:17:39.730Z"
    }
   },
   "outputs": [],
   "source": [
    "usersWithTermInProfile =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.172811Z",
     "start_time": "2018-04-06T23:17:39.738Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_rows_for_terms(wordFrame, experimentalTerms):\n",
    "    return wordFrame[wordFrame.term.isin(experimentalTerms)]\n",
    "\n",
    "EXP_TERMS_FILEPATH = '%s/Dropbox/PainNarrativesLab/Data/experimental-terms.xlsx' % BASE\n",
    "experimentalTerms = pd.read_excel(EXP_TERMS_FILEPATH, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.174327Z",
     "start_time": "2018-04-06T23:17:39.746Z"
    }
   },
   "outputs": [],
   "source": [
    "get_rows_for_terms(words, experimentalTerms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.175899Z",
     "start_time": "2018-04-06T23:17:40.038Z"
    }
   },
   "outputs": [],
   "source": [
    "from FileSystemTools import *\n",
    "from UtilityDecorators import *\n",
    "from UtilityFunctions import *\n",
    "\n",
    "\n",
    "BASE = getSystemRoot()\n",
    "LOG_FOLDER_PATH = \"%s/Desktop/TwitterDataAnalysisLogs\" %BASE\n",
    "DEFAULT_LOG_FILE_NAME = 'twitter_log.txt'\n",
    "DEFAULT_LOG_FILE_PATH = \"%s/%s\" % (LOG_FOLDER_PATH, DEFAULT_LOG_FILE_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.177965Z",
     "start_time": "2018-04-06T23:17:40.046Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd tweetloggers\n",
    "%run -i FileLoggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.180500Z",
     "start_time": "2018-04-06T23:17:40.054Z"
    }
   },
   "outputs": [],
   "source": [
    "%bookmark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T19:27:12.505549Z",
     "start_time": "2018-03-27T19:27:12.489133Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.182324Z",
     "start_time": "2018-04-06T23:17:40.062Z"
    }
   },
   "outputs": [],
   "source": [
    "f = FileWritingLogger(name='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.184720Z",
     "start_time": "2018-04-06T23:17:40.072Z"
    }
   },
   "outputs": [],
   "source": [
    "f.log('j')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.186722Z",
     "start_time": "2018-04-06T23:17:40.086Z"
    }
   },
   "outputs": [],
   "source": [
    "fwl = FileWritingLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.188741Z",
     "start_time": "2018-04-06T23:17:40.094Z"
    }
   },
   "outputs": [],
   "source": [
    "fwl.log('taco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.190787Z",
     "start_time": "2018-04-06T23:17:40.102Z"
    }
   },
   "outputs": [],
   "source": [
    "fwl2 = FileWritingLogger('new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.193368Z",
     "start_time": "2018-04-06T23:17:40.110Z"
    }
   },
   "outputs": [],
   "source": [
    "f.log_error('tacoooooo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.195541Z",
     "start_time": "2018-04-06T23:17:40.118Z"
    }
   },
   "outputs": [],
   "source": [
    "sol = StdOutLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.198167Z",
     "start_time": "2018-04-06T23:17:40.126Z"
    }
   },
   "outputs": [],
   "source": [
    "sol.log('taco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorize users by condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.200100Z",
     "start_time": "2018-04-06T23:17:40.504Z"
    }
   },
   "outputs": [],
   "source": [
    "# Determine number of valid users identified and number of tweets each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.202581Z",
     "start_time": "2018-04-06T23:17:40.512Z"
    }
   },
   "outputs": [],
   "source": [
    "stripNonAlphaNum('!jip!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.204561Z",
     "start_time": "2018-04-06T23:17:40.522Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "wordTokenizer = WordTokenizer()\n",
    "word_processor = SingleWordProcessor()\n",
    "\n",
    "\n",
    "word_processor.add_to_filters( TextProcessors.Filters.UsernameFilter( ) )\n",
    "word_processor.add_to_filters( TextProcessors.Filters.PunctuationFilter( ) )\n",
    "word_processor.add_to_filters( TextProcessors.Filters.URLFilter( ) )\n",
    "word_processor.add_to_filters( TextProcessors.Filters.NumeralFilter( ) )\n",
    "word_processor.add_to_modifiers( TextProcessors.Modifiers.WierdBPrefixConverter() )\n",
    "# processor.add_to_modifiers( TextProcessors.Modifiers.UnicodeConverter() )\n",
    "word_processor.add_to_modifiers( TextProcessors.Modifiers.CaseConverter( ) )\n",
    "\n",
    "\n",
    "# Create queue and listeners for processed tokens\n",
    "Queue = SaveQueueHandler()\n",
    "Queue.register_listener(SaveListener())\n",
    "\n",
    "# Load cursor for tweet ids\n",
    "cursor = DataTools.Cursors.TweetCursor()\n",
    "\n",
    "StringProcessingWorker.initialize(cursor, Queue, word_processor)\n",
    "threads = []\n",
    "\n",
    "# for _ in range(1):\n",
    "worker = StringProcessingWorker()\n",
    "# worker.do_it()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.206310Z",
     "start_time": "2018-04-06T23:17:40.532Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd textanalysis\n",
    "%run -i ProcessingTools/SearchTools.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.207954Z",
     "start_time": "2018-04-06T23:17:40.540Z"
    }
   },
   "outputs": [],
   "source": [
    "s = Searcher()\n",
    "spoonie_results = s.search('Spoonie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.209540Z",
     "start_time": "2018-04-06T23:17:40.552Z"
    }
   },
   "outputs": [],
   "source": [
    "# This cell was imported from twitter_data_analysis 11/9/16 \n",
    "%cd textanalysis\n",
    "%run -i ProcessingTools/SearchTools.py\n",
    "\n",
    "# \\section{Word frequency}\n",
    "# freq = pd.read_excel(\"%s/freq_wordlist.xlsx\" % DATAFOLDER)\n",
    "# len(freq)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# freq.freq.hist(ax=ax, bins=100, bottom=0.1)\n",
    "# ax.set_yscale('log')\n",
    "# ax.set_title(\"Term frequency in user profiles\")\n",
    "\n",
    "# trimmed_freq = freq[freq.freq > 1000]\n",
    "# len(trimmed_freq)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# trimmed_freq.freq.hist(ax=ax, bins=100, bottom=0.1)\n",
    "# ax.set_yscale('log')\n",
    "# ax.set_title(\"Term frequency in user profiles\")\n",
    "\n",
    "from beautifulsoup4.BeautifulSoup import BeautifulStoneSoup\n",
    "\n",
    "def formatter(text):\n",
    "    try:\n",
    "        return unicode(BeautifulStoneSoup(text, convertEntities=BeautifulStoneSoup.ALL_ENTITIES))\n",
    "    except:\n",
    "        print (\"Error %s\" % text)\n",
    "        return ''\n",
    "\n",
    "\n",
    "trimmed_freq['word'] = trimmed_freq['word'].map(lambda x: formatter(x))\n",
    "\n",
    "trimmed_freq.sort('freq', ascending=False)[:10]\n",
    "\n",
    "fibro_aliases = ['Fibromyalgia', 'Fibro', 'fibro*']\n",
    "for t in fibro_aliases:\n",
    "    fibro = condition_searcher(t, fibro)\n",
    "\n",
    "crps = Condition('crps')\n",
    "crps_aliases = ['crps', 'RSD', 'c.r.p.s.', 'r.s.d.', 'complex regional pain syndrome', 'reflex sympathetic dystrophy']\n",
    "for t in crps_aliases:\n",
    "    crps = condition_searcher(t, crps)\n",
    "\n",
    "import numpy\n",
    "d = numpy.genfromtxt('/Users/adam/Desktop/freq_wordlist.txt')\n",
    "\n",
    "import asciitable\n",
    "h = DataFrame(asciitable.read('/Users/adam/Desktop/freq_wordlist.txt'))\n",
    "\n",
    "dt = pd.read_table('/Users/adam/Desktop/freq_wordlist.csv', delim_whitespace=True, encoding='utf-8')\n",
    "\n",
    "dt = dt.applymap(lambda x: x['word'].encode('ascii', 'replace'))\n",
    "\n",
    "s = Searcher()\n",
    "crps_results = s.search('((crps) | (RSD) | (r.s.d.) | (c.r.p.s.) | (complex regional pain syndrome) | (chronic regional pain syndrome) | (reflex sympathetic dystrophy))')\n",
    "s = Searcher()\n",
    "migraine_results = s.search('((migraine) | (Migraineur) | (migr*))')\n",
    "s = Searcher()\n",
    "fibro_results = s.search('((Fibromyalgia) | (Fibro) | (fibro*) | (fm) | (fms))')\n",
    "s = Searcher()\n",
    "spoonie_results = s.search('Spoonie')\n",
    "s = Searcher()\n",
    "vulvodynia_results = s.search('Vulvodynia | Vulvadynia')\n",
    "s = Searcher()\n",
    "endo_results = s.search('endometriosis | endo')\n",
    "s = Searcher()\n",
    "neuropathy_results = s.search('neuropathy')\n",
    "s = Searcher()\n",
    "arthritis_results = s.search('((arthritis) | (*arthritis) | (oa) | (ra))' )\n",
    "s = Searcher()\n",
    "neuralgia_results = s.search('(neuralgia) | (*neuralgia)')\n",
    "s = Searcher()\n",
    "shingles_results = s.search('((shingles) | (post-herpetic neuralgia) | (PHN))')\n",
    "s = Searcher()\n",
    "backpain_results = s.search('(back pain | backpain)')\n",
    "s = Searcher()\n",
    "headache = s.search('headache')\n",
    "\n",
    "migraine_users = ug.get_from_list('migraine', migraine_results['userids'])\n",
    "crps_users = ug.get_from_list('crps', crps_results['userids'])\n",
    "fibro_users = ug.get_from_list('fibromyalgia', fibro_results['userids'])\n",
    "spoonie_users = ug.get_from_list('spoonie', spoonie_results['userids'])\n",
    "vulvodynia_users = ug.get_from_list('vulvodynia', vulvodynia_results['userids'])\n",
    "endo_users = ug.get_from_list('endometriosis', endo_results['userids'])\n",
    "neuropathy_users = ug.get_from_list('neuropathy', neuropathy_results['userids'])\n",
    "arthritis_users = ug.get_from_list('arthritis', arthritis_results['userids'])\n",
    "neuralgia_users = ug.get_from_list('neuralgia', neuralgia_results['userids'])\n",
    "shingles_users = ug.get_from_list('shingles', shingles_results['userids'])\n",
    "backpain_users = ug.get_from_list('backpain', backpain_results['userids'])\n",
    "\n",
    "migraine_users.to_csv('%s/migraine.csv' % DATAFOLDER)\n",
    "crps_users.to_csv('%s/crps.csv' % DATAFOLDER)\n",
    "fibro_users.to_csv('%s/fibromyalgia.csv' % DATAFOLDER)\n",
    "spoonie_users.to_csv('%s/spoonie.csv' % DATAFOLDER)\n",
    "vulvodynia_users.to_csv('%s/vulvodynia.csv' % DATAFOLDER)\n",
    "endo_users.to_csv('%s/endo.csv' % DATAFOLDER)\n",
    "neuropathy_users.to_csv('%s/neuropathy.csv' % DATAFOLDER)\n",
    "arthritis_users.to_csv('%s/arthritis.csv' % DATAFOLDER)\n",
    "neuralgia_users.to_csv('%s/neuralgia.csv' % DATAFOLDER)\n",
    "shingles_users.to_csv('%s/shingles.csv' % DATAFOLDER)\n",
    "backpain_users.to_csv('%s/backpain.csv' % DATAFOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.210922Z",
     "start_time": "2018-04-06T23:17:40.564Z"
    }
   },
   "outputs": [],
   "source": [
    "j='jjj'\n",
    "print(\"%s\" % j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.212518Z",
     "start_time": "2018-04-06T23:17:40.574Z"
    }
   },
   "outputs": [],
   "source": [
    "TextTools.TextFilters.remove_numerals(\"7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.214505Z",
     "start_time": "2018-04-06T23:17:40.584Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Used to be in FILEFOLDER = '%s/Desktop/user_categories' % BASE\n",
    "Moved into Data folder in pain narratives lab\n",
    "\"\"\"\n",
    "def file_getter(filefolder=FILEFOLDER):\n",
    "    \"\"\"\n",
    "    Loads the the files in the folder    \n",
    "    Args:\n",
    "        filefolder: Folder path for where all the folders are stored\n",
    "    \n",
    "    Returns:\n",
    "        Dataframe\n",
    "    \"\"\"\n",
    "    datafiles = []\n",
    "    sourceFolder = os.walk(filefolder)\n",
    "    for f in sourceFolder:\n",
    "        filelist = f[2]\n",
    "        for fl in filelist:\n",
    "            fl = str(fl)\n",
    "            #if fl is not '.DS_Store':\n",
    "            if fl[-5:] == '.xlsx':\n",
    "                print (fl)\n",
    "                loc = filefolder + '/' + str(fl)\n",
    "                datafiles.append(loc)\n",
    "    return datafiles\n",
    "\n",
    "\n",
    "def cat_importer(filenames):\n",
    "    \"\"\"\n",
    "    Import spreadsheets with categorizations of users, \n",
    "    combine them, and return the result\n",
    "        \n",
    "    Args:\n",
    "        filenames: List of full path excel files\n",
    "    \n",
    "    Returns:\n",
    "        Dataframe\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for f in filenames:\n",
    "        try:\n",
    "            frames.append(pd.read_excel(f))\n",
    "        except:\n",
    "            print (\"error with %s\" % f)\n",
    "    combined = pd.concat(frames)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.216741Z",
     "start_time": "2018-04-06T23:17:40.594Z"
    }
   },
   "outputs": [],
   "source": [
    "files = file_getter()\n",
    "compiled = cat_importer(files)\n",
    "print (len(compiled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.218942Z",
     "start_time": "2018-04-06T23:17:40.612Z"
    }
   },
   "outputs": [],
   "source": [
    "compiled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.220531Z",
     "start_time": "2018-04-06T23:17:40.622Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make frames with categorized users\n",
    "compiled = compiled[compiled.relevant == 1]\n",
    "patients = compiled[compiled.patient == 1]\n",
    "clinicians = compiled[compiled.clinician == 1]\n",
    "\n",
    "# Separate by condition\n",
    "patients_by_condition = patients.groupby('term')\n",
    "clinicians_by_condition = clinicians.groupby('term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.222163Z",
     "start_time": "2018-04-06T23:17:40.632Z"
    }
   },
   "outputs": [],
   "source": [
    "for g, n in patients_by_condition:\n",
    "    print(g, len(n)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.223605Z",
     "start_time": "2018-04-06T23:17:40.642Z"
    }
   },
   "outputs": [],
   "source": [
    "migraine_bag = []\n",
    "m = patients_by_condition.get_group('migraine')\n",
    "for i in m.profile:\n",
    "    migraine_bag.append(word_tokenize(i))\n",
    "#for p in m:\n",
    "#    migraine_bag.append(word_tokenize(p.profile))\n",
    "print(len(migraine_bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.225242Z",
     "start_time": "2018-04-06T23:17:40.654Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "bagmaker = TextTools.WordBagMaker()\n",
    "bagmaker.add_to_ignorelist(ConstantsAndUtilities.Ignore.get_list())\n",
    "bagmaker.add_to_ignorelist(list(string.punctuation))\n",
    "bagmaker.add_to_ignorelist(nltk.corpus.stopwords.words('english'))\n",
    "bagmaker.add_to_cleaners(TextTools.URLCleaner())\n",
    "#bagmaker.add_to_cleaners(TextTools.NumeralCleaner())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.226857Z",
     "start_time": "2018-04-06T23:17:40.664Z"
    }
   },
   "outputs": [],
   "source": [
    "'3'.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.228050Z",
     "start_time": "2018-04-06T23:17:40.672Z"
    }
   },
   "outputs": [],
   "source": [
    "nc = TextTools.NumeralCleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.229574Z",
     "start_time": "2018-04-06T23:17:40.682Z"
    }
   },
   "outputs": [],
   "source": [
    "nc.clean('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.231934Z",
     "start_time": "2018-04-06T23:17:40.692Z"
    }
   },
   "outputs": [],
   "source": [
    "m = patients_by_condition.get_group('migraine')\n",
    "pw = [w for w in m.profile]\n",
    "\n",
    "bagmaker.process(pw)\n",
    "print(len(bagmaker.masterbag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.234663Z",
     "start_time": "2018-04-06T23:17:40.704Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bagmaker.masterbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.236580Z",
     "start_time": "2018-04-06T23:17:40.714Z"
    }
   },
   "outputs": [],
   "source": [
    "wf = TextStats.WordFreq(bagmaker.masterbag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.238232Z",
     "start_time": "2018-04-06T23:17:40.722Z"
    }
   },
   "outputs": [],
   "source": [
    "wf.topN(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.240123Z",
     "start_time": "2018-04-06T23:17:40.738Z"
    }
   },
   "outputs": [],
   "source": [
    "wf.plot(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.241800Z",
     "start_time": "2018-04-06T23:17:40.746Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mb = tuple(migraine_bag)\n",
    "mfd = nltk.FreqDist(mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T23:17:41.245071Z",
     "start_time": "2018-04-06T23:17:40.982Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd twitteranalysis\n",
    "import DataTools.Cursors\n",
    "\n",
    "# Create tables in database\n",
    "from DataTools.TweetORM import create_db_tables\n",
    "# create_db_tables()\n",
    "\n",
    "#%cd /Users/adam/Dropbox/PainNarrativesLab/TwitterDataAnalysis\n",
    "#%bookmark twitteranalysis\n",
    "%cd twitteranalysis\n",
    "%run -i environment.py\n",
    "%run -i ConstantsAndUtilities.py\n",
    "%run -i TestingTools/DataAndFunctionsForTesting.py\n",
    "%run -i \"DataTools/DataStructures.py\"\n",
    "%run -i \"DataTools/DataConnections.py\"\n",
    "%run -i \"DataTools/WordORM.py\"\n",
    "%run -i \"DataTools/DataRepositories.py\" \n",
    "\n",
    "# Initialize the tools for filtering and modifying the individual tweet words\n",
    "from TextProcessors.Filters import *\n",
    "from TextProcessors.Modifiers import *\n",
    "%cd texttools\n",
    "%run -i TextProcessors/Processors\n",
    "%run -i TextProcessors/Tokenizers\n",
    "\n",
    "%run -i ProcessingTools/ProcessingControllers.py\n",
    "%run -i ProcessingTools/Listeners.py\n",
    "%run -i ProcessingTools/Workers.py\n",
    "import DataTools.Cursors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "68px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
